# ML Notes - 1

## Types of Algorithm Output

- _Regression_: Algorithm attempts to map set of input-feature(s) _x_ to a **continuous value** output _y_ . In contrast to a Classification algorithm which attempts to predict discreet class labels (e.g. true or false). Regression algorithms can of course also predict discreet values in the form of integers (for instance). Ex: _NavLab_ autonomous vehicle from Carnegie-Mellon uses regression to map the sensor input of the road to the continuous-output _y_ that the human labels through the training phase. (in other words there is no set of discreet values for a steering wheel to be put in..). Another classic example would be mapping things like house sqare-footage to sale-value.

- _Classification_: Algorithm attempts to map a function from set of input-features(s) _x_ to a **discreet value (class/label)** output _y_. Similar to how there is overlap with Regression algo's (having discreet outputs in the event of integers). Classification algos can also have continuous value outputs if they are used as labels/classes during training. A classic example would be an algorithm mapping input features of tumor size to output classes of either malignant, or benign. There is a discreet set of possible outputs, either yes, or no. (there can be any number of discreet values, and hence there is overlap between the two algorithms).

## Supervised Learning

#### Description

- "Supervised learning (SL) is a paradigm in machine learning where input objects (for example, a vector of predictor variables) and a desired output value (also known as human-labeled supervisory signal) train a model. The training data is processed, building a function that maps new data on expected output values."

#### Definitions

- _Features_: Features are _'x1,x2,...' values_ . The dimensions of input data for _supervised_ learning.

- _Labels_: Outputs _Y_ . Job of ML algorithm is to map _Labels_ to _Features_

## Unsupervised Learning

#### Description

- Basically your leaning algorithm will attempt to make sense of inputs _x_ on it's own. Having no _y_ _labeling_ from a human.

#### Definitions

- _Clustering_: This is the algorithm used by Google News for instance to crawl news sites, and group together articles based on how close they cluster in subject matter.

---

## Basic Supervised Linear Regression Algorithm

#### Supervised Learning 'Work-Flow'

- **Training Set**: Your dataset. This step will involve several sub-steps like _data-cleaning_, and _feature-scaling_ among others.
  ->
- **Learning Algorithm**: The prepared _training set_ of data is fed into the learning algorithm, who's job it is to output the _function_ that will make the predictions sought.
  ->
- **Hypothesis** (function that makes prediction). Hypothesis is the function which then will take in unknown inputs (inputs not in the original training set) and produce the prediction outputs.

#### Mathemtatical Representation

$$ h(x) = \theta_0 + \theta_1x_1 + \theta_2x_2... $$

Where:

- $h(x)$ or _y_: Is the function output, the predicted value.
- $\theta_0$: Is the y-intercept. The predicted value of y when x is at origin (0).
- $\theta_1$: Is the regression coefficient. The amount of change in predicted in y for increases/decreases in x (If you only have 1 feature/independent variable, this is it.)
- $x_1$: The independent variable or _feature_ set. With just 1 feature, this would be the only _x_ .. however that's rarely the case.. thus ->
- $\theta_2$: Is the 2nd (of _n_-possible) regression coefficients to the ->
- $x_2$: Is the 2nd feature set or independent variable set.
- ... and so on for increasing dimensions of features

#### Process

- You first want to ask yourself when designing the **Learning Algorithm** _"How do we want to represent the **Hypothesis(function)**?"_
